
# VRQA - Vision Reasoning Question Answering

**Innovative XR-based question answering system using Reasoning LLMs and first-person perspective sharing.**

## Overview

VRQA is a groundbreaking project that seamlessly integrates XR (Extended Reality) headset technology with the power of advanced Reasoning Large Language Models (LLMs). By capturing and sharing the user's first-person perspective within a virtual or augmented environment, VRQA enables users to ask contextually relevant questions based on their real-time visual experience.

## Key Features

*   **First-Person Perspective Sharing:** Dynamically captures and transmits the user's field of view, providing crucial visual context to the LLM for accurate and relevant responses.

*   **Reasoning LLM Integration:** Leverages cutting-edge LLMs (Gemini 2.0) capable of sophisticated reasoning and contextual understanding.
*   **Immersive Interaction:** Facilitates natural language question-asking within XR environments, enhancing user immersion and engagement.
*   **Multi-Modal Input Support (Optional):** Supports diverse input modalities such as voice commands and environment recognition for more intuitive interaction.


[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT) 
